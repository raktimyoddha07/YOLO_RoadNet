{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0873fa-2b0a-4e92-8c9a-6b0ae35392cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video: 100%|██████████| 1224/1224 [04:46<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in C:\\Users\\rakti\\Downloads\\a\\YOLO\\Object-Detection-with-YOLO-and-Data-Filtering-main\\new_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Config:\n",
    "    # Path configurations\n",
    "    VIDEO_PATH = r\"C:\\Users\\rakti\\Downloads\\a\\YOLO\\Object-Detection-with-YOLO-and-Data-Filtering-main\\task_video.mp4\"\n",
    "    OUTPUT_DIR = r\"C:\\Users\\rakti\\Downloads\\a\\YOLO\\Object-Detection-with-YOLO-and-Data-Filtering-main\"\n",
    "    NEW_DATASET_DIR = os.path.join(OUTPUT_DIR, \"new_dataset\")\n",
    "    MODEL_PATH = \"/content/yolov8n.pt\"\n",
    "\n",
    "    # Detection parameters\n",
    "    CONFIDENCE_THRESH = 0.3\n",
    "    IOU_THRESH = 0.5\n",
    "\n",
    "    # Class settings\n",
    "    VEHICLE_CLASSES = ['car', 'bus', 'truck', 'motorcycle']\n",
    "    PERSON_CLASS = 'person'\n",
    "\n",
    "    # Delay (in seconds) after processing each frame to give the model more time\n",
    "    FRAME_PROCESSING_DELAY = 0.1\n",
    "\n",
    "def process_detections(results, vehicle_classes):\n",
    "    \"\"\"Process YOLO results and separate vehicles/persons.\"\"\"\n",
    "    vehicles = []\n",
    "    persons = []\n",
    "    detections = []\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            if box.conf < Config.CONFIDENCE_THRESH:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls_id = int(box.cls)\n",
    "            cls_name = result.names[cls_id]\n",
    "\n",
    "            if cls_name in vehicle_classes:\n",
    "                vehicles.append((x1, y1, x2, y2))\n",
    "                detections.append((cls_id, x1, y1, x2, y2))\n",
    "            elif cls_name == Config.PERSON_CLASS:\n",
    "                persons.append((x1, y1, x2, y2))\n",
    "\n",
    "    return vehicles, persons, detections\n",
    "\n",
    "def filter_persons(persons, vehicles, person_cls_id):\n",
    "\n",
    "    filtered = []\n",
    "    for (x1, y1, x2, y2) in persons:\n",
    "        center_x = (x1 + x2) / 2.0\n",
    "        center_y = (y1 + y2) / 2.0\n",
    "        inside = False\n",
    "        for (vx1, vy1, vx2, vy2) in vehicles:\n",
    "            if vx1 <= center_x <= vx2 and vy1 <= center_y <= vy2:\n",
    "                inside = True\n",
    "                break\n",
    "        if not inside:\n",
    "            filtered.append((person_cls_id, x1, y1, x2, y2))\n",
    "    return filtered\n",
    "\n",
    "def run_object_detection():\n",
    "    # Initialize model and video\n",
    "    model = YOLO(Config.MODEL_PATH)\n",
    "    cap = cv2.VideoCapture(Config.VIDEO_PATH)\n",
    "\n",
    "    # Get the class id for the person class\n",
    "    person_cls_id = None\n",
    "    for cls_id, name in model.names.items():\n",
    "        if name == Config.PERSON_CLASS:\n",
    "            person_cls_id = cls_id\n",
    "            break\n",
    "    if person_cls_id is None:\n",
    "        raise ValueError(\"Person class not found in model\")\n",
    "\n",
    "    # Create new dataset directory and its subdirectories\n",
    "    os.makedirs(Config.NEW_DATASET_DIR, exist_ok=True)\n",
    "    img_dir = os.path.join(Config.NEW_DATASET_DIR, \"images\")\n",
    "    label_dir = os.path.join(Config.NEW_DATASET_DIR, \"labels\")\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"Processing video\") as pbar:\n",
    "        frame_count = 0\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # Run object detection on the frame\n",
    "            results = model(frame, conf=Config.CONFIDENCE_THRESH,\n",
    "                           iou=Config.IOU_THRESH, verbose=False)\n",
    "\n",
    "            # Process detections: separate vehicles and persons\n",
    "            vehicles, persons, detections = process_detections(results, Config.VEHICLE_CLASSES)\n",
    "\n",
    "            # Filter out persons that are inside a detected vehicle\n",
    "            filtered_persons = filter_persons(persons, vehicles, person_cls_id)\n",
    "            final_detections = detections + filtered_persons\n",
    "\n",
    "            # YOLO format\n",
    "            height, width = frame.shape[:2]\n",
    "            img_path = os.path.join(img_dir, f\"{frame_count:04d}.jpg\")\n",
    "            label_path = os.path.join(label_dir, f\"{frame_count:04d}.txt\")\n",
    "\n",
    "            cv2.imwrite(img_path, frame)\n",
    "\n",
    "            with open(label_path, \"w\") as f:\n",
    "                for detection in final_detections:\n",
    "                    cls_id, x1, y1, x2, y2 = detection\n",
    "                    x_center = (x1 + x2) / (2.0 * width)\n",
    "                    y_center = (y1 + y2) / (2.0 * height)\n",
    "                    w = (x2 - x1) / width\n",
    "                    h = (y2 - y1) / height\n",
    "                    f.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Adding a short delay to ensure each frame is processed properly\n",
    "            time.sleep(Config.FRAME_PROCESSING_DELAY)\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Results saved in {Config.NEW_DATASET_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_object_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675771bd-7c25-46ff-9820-f58d11cae96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing images: 100%|██████████| 1224/1224 [00:20<00:00, 60.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations saved in C:\\Users\\rakti\\Downloads\\a\\YOLO\\Object-Detection-with-YOLO-and-Data-Filtering-main\\new_dataset\\visualizations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "OUTPUT_DIR = r\"C:\\Users\\rakti\\Downloads\\a\\YOLO\\Object-Detection-with-YOLO-and-Data-Filtering-main\"\n",
    "NEW_DATASET_DIR = os.path.join(OUTPUT_DIR, \"new_dataset\")\n",
    "VISUALIZATION_DIR = os.path.join(NEW_DATASET_DIR, \"visualizations\")\n",
    "MODEL_PATH = \"/content/yolov8n.pt\"\n",
    "\n",
    "CLASS_COLORS = {\n",
    "    'person': (0, 255, 0),\n",
    "    'car': (255, 0, 0),\n",
    "    'motorcycle': (255, 255, 0),\n",
    "    'bus': (0, 255, 255),\n",
    "    'truck': (255, 0, 255)\n",
    "}\n",
    "\n",
    "def visualize_results():\n",
    "\n",
    "    os.makedirs(VISUALIZATION_DIR, exist_ok=True)\n",
    "\n",
    "    # Load model for class names\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    class_names = model.names\n",
    "\n",
    "    img_dir = os.path.join(NEW_DATASET_DIR, \"images\")\n",
    "    label_dir = os.path.join(NEW_DATASET_DIR, \"labels\")\n",
    "\n",
    "    image_files = sorted(os.listdir(img_dir))\n",
    "\n",
    "    for img_file in tqdm(image_files, desc=\"Visualizing images\"):\n",
    "        img_path = os.path.join(img_dir, img_file)\n",
    "        label_path = os.path.join(label_dir, img_file.replace(\".jpg\", \".txt\"))\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) != 5:\n",
    "                        continue\n",
    "                    cls_id, x_center, y_center, w, h = map(float, parts)\n",
    "                    cls_name = class_names[int(cls_id)]\n",
    "\n",
    "                    # Convert from YOLO format to absolute coordinates\n",
    "                    x1 = int((x_center - w/2) * width)\n",
    "                    y1 = int((y_center - h/2) * height)\n",
    "                    x2 = int((x_center + w/2) * width)\n",
    "                    y2 = int((y_center + h/2) * height)\n",
    "\n",
    "                    color = CLASS_COLORS.get(cls_name, (255, 255, 255))\n",
    "                    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(image, cls_name, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Save the visualized image\n",
    "        vis_path = os.path.join(VISUALIZATION_DIR, img_file)\n",
    "        cv2.imwrite(vis_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(f\"Visualizations saved in {VISUALIZATION_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a4e85-becb-4ba0-957a-dda453c4b4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
